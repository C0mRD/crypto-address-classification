{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataaset with features\n",
    "df = pd.read_csv(\"../dataset/processed_data/dataset_with_feature_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features to numerical values\n",
    "# df = pd.get_dummies(df, columns=['prefix', 'checksum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['prefix'] = le.fit_transform(df['prefix'])\n",
    "# df['checksum'] = le.fit_transform(df['checksum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['prefix', 'checksum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"trydata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for target\n",
    "df['type'] = le.fit_transform(df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=['address', 'type'])\n",
    "y = df['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save class information for inference\n",
    "np.save('../models/classes.npy', le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to train\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=150, random_state=62),\n",
    "    # \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=58),\n",
    "    \"SVC\": SVC(random_state=42),\n",
    "    # \"DecisionTree\": DecisionTreeClassifier(random_state=23),\n",
    "    \"NaiveBayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(model, f\"../models/{model_name}.pkl\")\n",
    "    print(f\"{model_name} model saved as {model_name}.pkl\\n\")\n",
    "\n",
    "    # Save Random Forest model to a variable for later use\n",
    "    if model_name == \"RandomForest\":\n",
    "        rf_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "nn_model = Sequential([\n",
    "    Dense(32, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')  # Output layer with 3 neurons for 3 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "nn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = nn_model.fit(X_train, y_train, epochs=2, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = nn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Neural Network Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nn_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report for Neural Network:\")\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "# Save the trained neural network model\n",
    "nn_model.save(\"../models/neural_network_model.keras\")\n",
    "print(\"Neural Network model saved as neural_network_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check feature importance\n",
    "# Get feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "feature_names = df.drop(columns=['address', 'type']).columns\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "plt.title('Feature Importance with respect to Target Variable')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hornetassign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
